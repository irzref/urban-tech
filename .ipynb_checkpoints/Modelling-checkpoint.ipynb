{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KD-Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial.KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = np.mgrid[0:5, 2:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(zip(x.ravel(), y.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.square(0.1) + np.square(0.1) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = spatial.KDTree(list(zip(x.ravel(), y.ravel())))\n",
    "pts = np.array([[0, 0], [2.1, 2.9]])\n",
    "tree.query(pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Euclidian Distance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reading csv from one hot encoded csv dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "test_df = pd.read_csv(\"../herbarium-berlin-oneh.csv.gz\",compression='gzip', encoding='utf-8', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = pdist(test_df, 'euclidean')\n",
    "# dist_df = pd.DataFrame(squareform(dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import DistanceMetric\n",
    "\n",
    "dist = DistanceMetric.get_metric('euclidean')\n",
    "\n",
    "X = [[0, 1, 2],[3, 4, 5]]\n",
    "dist.pairwise(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.pairwise(test_df.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reading csv from clean csv dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "item_df_dr_0 = pd.read_csv(\"../herbarium-berlin-clean.csv\", sep = '\\t', index_col=False)\n",
    "item_df_dr_0 = item_df_dr_0.drop(item_df_dr_0.columns[0], axis=1)\n",
    "\n",
    "cal_btc_df = item_df_dr_0[[\"kingdom\",\"phylum\",\"class\",\"order\",\"family\",\"genus\",\"species\",\"decimalLatitude\",\"decimalLongitude\"]]\n",
    "oneh_cal_btc_df = pd.get_dummies(cal_btc_df,prefix=['kingdom','phylum','class','order','family','genus','species'])\n",
    "oneh_cal_btc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_df_dr_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneh_cal_btc_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import DistanceMetric\n",
    "\n",
    "dist = DistanceMetric.get_metric('euclidean')\n",
    "dist.pairwise(oneh_cal_btc_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy import sparse\n",
    "\n",
    "sparse_df = oneh_cal_btc_df.to_sparse(fill_value=0)\n",
    "X = sparse.csr_matrix(sparse_df.to_coo())\n",
    "\n",
    "res = euclidean_distances(X, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = oneh_cal_btc_df.to_sparse(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sparse_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dot product method derived from the releation between euclidean distance and dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy import sparse\n",
    "\n",
    "sparse_df = oneh_cal_btc_df.to_sparse(fill_value=0)\n",
    "X = sparse.csr_matrix(sparse_df.to_coo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_norm = scaler.fit_transform(X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm.dot(X_norm[0,:].T).toarray().flatten().argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = X_norm.T.dot(X_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = similarities.argsort(axis=1)[:,-10:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.dot(X[0,:].T).toarray().flatten().argsort()[1:5]\n",
    "res0 = X.dot(X[0,:].T).toarray().flatten().argsort()\n",
    "res0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(res0==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = X.dot(X[1,:].T).toarray().flatten().argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(res1==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[173283]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_df_dr_0.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_df_dr_0.iloc[88]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def sparse_similarity(X,top_k=5):\n",
    "        \n",
    "    #scaler = StandardScaler(with_mean=False)\n",
    "    #X_norm = scaler.fit_transform(X.T).T\n",
    "\n",
    "    return [X.dot(X[i,:].T).toarray().flatten().argsort()[1:top_k] for i in range(X.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smlrt = sparse_similarity(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "','.join(str(e) for e in X.dot(X[1,:].T).toarray().flatten().argsort()[1:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range(X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hs = open(\"../similar-result.txt\",\"a\")\n",
    "\n",
    "with open(\"../similar-result.txt\",\"a\") as hs:\n",
    "\n",
    "    for i in range(X.shape[0]):\n",
    "    \n",
    "        hs.write(','.join(str(e) for e in X.dot(X[i,:].T).toarray().flatten().argsort()[1:20]) + \"\\n\")\n",
    "        #hs.write(\"1 \\n\")\n",
    "    \n",
    "#hs.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Normalization for dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.random.randn(100) * 5 + 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "x_norm = normalize([x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_norm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_norm[0] @ x_norm[0].T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_x_norm = normalize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_x_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "sparse_df = test_df.to_sparse(fill_value=0)\n",
    "X = sparse.csr_matrix(sparse_df.to_coo())\n",
    "\n",
    "x_norm = normalize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_norm.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(x_norm.shape[0]):\n",
    "    \n",
    "        #hs.write(','.join(str(e) for e in X.dot(X[i,:].T).toarray().flatten().argsort()[1:20]) + \"\\n\")\n",
    "        print(','.join(str(e) for e in x_norm.dot(x_norm[i,:].T).toarray().flatten().argsort()[::-1][0:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "item_df_dr_0.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_df_dr_0.iloc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_df_dr_0.iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculating only on the taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tax_oneh_cal_btc_df = oneh_cal_btc_df.drop(columns=['decimalLatitude', 'decimalLongitude'])\n",
    "tax_oneh_cal_btc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df = tax_oneh_cal_btc_df.to_sparse(fill_value=0)\n",
    "X = sparse.csr_matrix(sparse_df.to_coo())\n",
    "\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_norm = scaler.fit_transform(X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = X_norm.T.dot(X_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chunk calculating euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = oneh_cal_btc_df.iloc[:10]\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oneh_cal_btc_df.iloc[0].values - oneh_cal_btc_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LA.norm(oneh_cal_btc_df.iloc[0].values - oneh_cal_btc_df.values, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ed(val_array, main_df):\n",
    "    sim_res = np.array([])\n",
    "    \n",
    "    for index, row in main_df.iterrows():\n",
    "        dis = LA.norm(row.values - val_array)\n",
    "        sim_res = np.append(sim_res, dis)\n",
    "    \n",
    "    #LA.norm(row.values - main_df.values, axis=1)\n",
    "    \n",
    "    return np.argsort(sim_res)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_item_array = []\n",
    "#used_df = oneh_cal_btc_df\n",
    "used_df = test_df\n",
    "\n",
    "for index, row in used_df.iterrows():\n",
    "    #print(\"row : \" + str(index), end='\\r')\n",
    "    res = calculate_ed(row.values, used_df)\n",
    "    similar_item_array.append(res)\n",
    "    \n",
    "    \n",
    "end_result = np.array(similar_item_array)\n",
    "#df1 = pd.DataFrame(end_result)\n",
    "#df1.to_csv(\"../result-similarity.csv\", encoding='utf-8', header=False, index=False)\n",
    "end_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_item_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(end_result)\n",
    "df1.to_csv(\"../test-similarity.csv\", encoding='utf-8', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_df = test_df\n",
    "\n",
    "with open(\"../test-similar-result.csv\",\"a\") as hs:\n",
    "\n",
    "    for index, row in used_df.iterrows():\n",
    "        #print(\"row : \" + str(index), end='\\r')\n",
    "        res = calculate_ed(row.values, used_df)\n",
    "        #similar_item_array.append(res)\n",
    "        \n",
    "        hs.write(','.join(str(e) for e in res) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"../caled-similar-result.csv\", header=None, index_col=False)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import linalg as LA\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# reading the dataset\n",
    "item_df_dr_0 = pd.read_csv(\"../herbarium-berlin-clean.csv\", sep = '\\t', index_col=False)\n",
    "item_df_dr_0 = item_df_dr_0.drop(item_df_dr_0.columns[0], axis=1)\n",
    "\n",
    "cal_btc_df = item_df_dr_0[[\"kingdom\",\"phylum\",\"class\",\"order\",\"family\",\"genus\",\"species\",\"decimalLatitude\",\"decimalLongitude\"]]\n",
    "oneh_cal_btc_df = pd.get_dummies(cal_btc_df,prefix=['kingdom','phylum','class','order','family','genus','species'])\n",
    "\n",
    "\n",
    "# method to calculate the euclidean distance for each row\n",
    "def calculate_ed(val_array, main_df):\n",
    "    sim_res = np.array([])\n",
    "    \n",
    "    for j in range(main_df.shape[0]):\n",
    "    #for index, row in main_df.iterrows():\n",
    "        dis = LA.norm(main_df.iloc[j].values - val_array)\n",
    "        sim_res = np.append(sim_res, dis)\n",
    "    \n",
    "    return np.argsort(sim_res)[:21]\n",
    "\n",
    "# test dataset\n",
    "test_df = oneh_cal_btc_df.iloc[:10]\n",
    "\n",
    "# loop through each dataset row\n",
    "similar_item_array = []\n",
    "#used_df = oneh_cal_btc_df\n",
    "used_df = test_df\n",
    "\n",
    "# calculate the similarity and take the 20 most similar items\n",
    "with open(\"../caled-similar-result.csv\",\"a\") as hs:\n",
    "\n",
    "    for i in range(used_df.shape[0]):\n",
    "    #for index, row in used_df.iterrows():\n",
    "        #print(\"row : \" + str(index), end='\\r')\n",
    "        #res = calculate_ed(row.values, used_df)\n",
    "        #similar_item_array.append(res)\n",
    "        \n",
    "        res = calculate_ed(oneh_cal_btc_df.iloc[i].values, used_df)\n",
    "        hs.write(','.join(str(e) for e in res) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneh_cal_btc_df.iloc[0].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
